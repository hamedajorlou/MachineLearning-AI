{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83P3GpgSCJvM",
        "outputId": "334ef03a-405a-441a-8a63-579b5aa965b6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1noatgYLCXhf"
      },
      "source": [
        "import os\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.model_selection import train_test_split\n",
        "path_happy= '/content/drive/MyDrive/Cohn-Kanade/happy'\n",
        "path_surprise = '/content/drive/MyDrive/Cohn-Kanade/surprise'\n",
        "path_disgust = '/content/drive/MyDrive/Cohn-Kanade/disgust'\n",
        "path_neutral = '/content/drive/MyDrive/Cohn-Kanade/neutral'\n",
        "hap_list = os.listdir(path_happy)\n",
        "surp_list = os.listdir(path_surprise)\n",
        "neu_list = os.listdir(path_neutral)\n",
        "disg_list = os.listdir(path_disgust)\n",
        "\n",
        "X_hap = []\n",
        "y_hap = []\n",
        "for i in hap_list :\n",
        "    X_hap.append(io.imread(os.path.join(path_happy,i),as_gray=True).flatten())\n",
        "    y_hap.append(0)\n",
        "\n",
        "X_surp = []\n",
        "y_surp = []\n",
        "\n",
        "for i in surp_list :\n",
        "    X_surp.append(io.imread(os.path.join(path_surprise,i),as_gray=True).flatten())\n",
        "    y_surp.append(1)\n",
        "\n",
        "X_disg = []\n",
        "y_disg = []\n",
        "\n",
        "for i in disg_list :\n",
        "    X_disg.append(io.imread(os.path.join(path_disgust,i),as_gray=True).flatten())\n",
        "    y_disg.append(2)\n",
        "\n",
        "X_neu = []\n",
        "y_neu = []\n",
        "\n",
        "for i in neu_list :\n",
        "    X_neu.append(io.imread(os.path.join(path_neutral,i),as_gray=True).flatten())\n",
        "    y_neu.append(3)\n",
        "\n",
        "X_hap = np.array(X_hap)\n",
        "X_surp = np.array(X_surp)\n",
        "X_disg = np.array(X_disg)\n",
        "X_neu = np.array(X_neu)\n",
        "X_hap_train, X_hap_test, y_hap_train, y_hap_test = train_test_split(X_hap, y_hap, train_size=60  ,shuffle=True, random_state=21)\n",
        "X_surp_train, X_surp_test, y_surp_train, y_surp_test = train_test_split(X_surp, y_surp, train_size=60  ,shuffle=True, random_state=21)\n",
        "X_neu_train, X_neu_test, y_neu_train, y_neu_test = train_test_split(X_neu, y_neu, train_size=120  ,shuffle=True, random_state=21)\n",
        "X_disg_train, X_disg_test, y_disg_train, y_disg_test = train_test_split(X_disg, y_disg, train_size=30  ,shuffle=True, random_state=21)\n",
        "X_train = np.concatenate((X_hap_train,X_surp_train,X_neu_train,X_disg_train))\n",
        "X_test = np.concatenate((X_hap_test,X_surp_test,X_disg_test,X_neu_test))\n",
        "y_train = np.concatenate((y_hap_train,y_surp_train,y_neu_train,y_disg_train))\n",
        "y_test = np.concatenate((y_hap_test,y_surp_test,y_disg_test,y_neu_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wqz5L9-RFGn4"
      },
      "source": [
        "Dataset is ready\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCiJS045FcnS",
        "outputId": "0eb02383-7119-4d4d-808f-1fb66303dbab"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "pca = PCA(n_components=100)\n",
        "pca.fit(X_train-np.mean(X_train,axis=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(n_components=100)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhLyqNdtGiHR"
      },
      "source": [
        "x_train_PCA =  pca.transform(X_train-np.mean(X_train,axis=0))\n",
        "x_test_PCA = pca.transform(X_test-np.mean(X_train,axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrESaRWMFJnP"
      },
      "source": [
        "Complexity Reduction using PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm9UDEQHHK26",
        "outputId": "b24370c1-671b-4bff-dbd3-5a7b9eb73c1c"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "X, y = make_classification(random_state=0)\n",
        "clf = make_pipeline(StandardScaler(),LinearSVC(C=100,random_state=0, tol=1e-5))\n",
        "clf.fit(x_train_PCA,y_train)\n",
        "y_pred = clf.predict(x_test_PCA)\n",
        "\n",
        "matrix = confusion_matrix(y_test,y_pred, labels=[3,2,1,0])\n",
        "print('Confusion matrix : \\n',matrix)\n",
        "\n",
        "tp, fn, fp, tn = confusion_matrix(y_test,y_pred,labels=[3,2,1,0])\n",
        "print('Outcome values : \\n', tp, fn, fp, tn)\n",
        "\n",
        "matrix = classification_report(y_test,y_pred,labels=[3,2,1,0])\n",
        "print('Classification report : \\n',matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix : \n",
            " [[25  8  9 28]\n",
            " [ 7  3  1  6]\n",
            " [12  1  9  6]\n",
            " [13  1  2  9]]\n",
            "Outcome values : \n",
            " [25  8  9 28] [7 3 1 6] [12  1  9  6] [13  1  2  9]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           3       0.44      0.36      0.39        70\n",
            "           2       0.23      0.18      0.20        17\n",
            "           1       0.43      0.32      0.37        28\n",
            "           0       0.18      0.36      0.24        25\n",
            "\n",
            "    accuracy                           0.33       140\n",
            "   macro avg       0.32      0.30      0.30       140\n",
            "weighted avg       0.37      0.33      0.34       140\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aqsAMzeNoXY",
        "outputId": "13236bc0-d811-4b0f-a4a3-3850a80ebd1a"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "x_train,y_train = shuffle(x_train_PCA,y_train)\n",
        "x_train_split = np.array(np.split(x_train,5))\n",
        "y_train_split = np.array(np.split(y_train,5 ))\n",
        "print(x_train_split.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 54, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSDwgA8WQ7J1"
      },
      "source": [
        "C = [0.01, 0.1, 1, 10, 100]\n",
        "mean = []\n",
        "for c in C : \n",
        "    s = []\n",
        "    for i in [0,1,2,3,4]:\n",
        "        f = [0,1,2,3,4]\n",
        "        f.remove(i)\n",
        "        x_test_fold1 = x_train_split[i , : , :]\n",
        "        y_test_fold1 = y_train_split[i , :]\n",
        "        x_train_fold1 = x_train_split[f, :]\n",
        "        x_train_fold1 = x_train_fold1.reshape(x_train_fold1.shape[0]*x_train_fold1.shape[1] , x_train_fold1.shape[2])\n",
        "        y_train_fold1 = y_train_split[f , :].flatten()\n",
        "        svc = LinearSVC(C = c , multi_class='ovr')\n",
        "        svc.fit(x_train_fold1,y_train_fold1)\n",
        "        s.append(svc.score(x_test_fold1,y_test_fold1))\n",
        "    mean.append(np.mean(s))\n",
        "C = C[np.argmax(mean)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sTrUJNOTw3p",
        "outputId": "6e178466-2c78-43e7-a9d7-d63937c154d8"
      },
      "source": [
        "print(f'optimal C is :', C )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimal C is : 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUVFJcpSVvMN",
        "outputId": "392e73e3-105d-4c8d-c087-95ac89895194"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(random_state=0)\n",
        "clf = make_pipeline(StandardScaler(),LinearSVC(C=0.01,random_state=0, tol=1e-5))\n",
        "clf.fit(x_train_PCA,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('linearsvc', LinearSVC(C=0.01, random_state=0, tol=1e-05))])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e53vearHcnf",
        "outputId": "d0f57179-3e8b-4c74-b374-40a615409055"
      },
      "source": [
        "y_pred = clf.predict(x_test_PCA)\n",
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140,)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVFXbH30IhEc",
        "outputId": "4cceb804-4ac4-4566-84b9-813459c8af93"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "matrix = confusion_matrix(y_test,y_pred, labels=[3,2,1,0])\n",
        "print('Confusion matrix : \\n',matrix)\n",
        "\n",
        "tp, fn, fp, tn = confusion_matrix(y_test,y_pred,labels=[3,2,1,0])\n",
        "print('Outcome values : \\n', tp, fn, fp, tn)\n",
        "\n",
        "matrix = classification_report(y_test,y_pred,labels=[3,2,1,0])\n",
        "print('Classification report : \\n',matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix : \n",
            " [[41  5 13 11]\n",
            " [ 5  2  4  6]\n",
            " [18  1  5  4]\n",
            " [17  3  4  1]]\n",
            "Outcome values : \n",
            " [41  5 13 11] [5 2 4 6] [18  1  5  4] [17  3  4  1]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           3       0.51      0.59      0.54        70\n",
            "           2       0.18      0.12      0.14        17\n",
            "           1       0.19      0.18      0.19        28\n",
            "           0       0.05      0.04      0.04        25\n",
            "\n",
            "    accuracy                           0.35       140\n",
            "   macro avg       0.23      0.23      0.23       140\n",
            "weighted avg       0.32      0.35      0.33       140\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuQcqwYS--P2"
      },
      "source": [
        "### as we see , accuracy rises , and new model is better than previous which we trained without insight on C ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHyZU11dgyzJ",
        "outputId": "4b527851-77cf-4b50-9edc-591c265547b2"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {'gamma':[0.000001,0.000004,0.000006,0.000008,0.00001], 'C':[0.01 , 0.1 , 1 , 10 , 100]}\n",
        "svc = SVC()\n",
        "clf = GridSearchCV(svc, parameters)\n",
        "clf.fit(x_train_PCA, y_train)\n",
        "clf.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.01, 'gamma': 1e-06}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV4CinGB_QhT"
      },
      "source": [
        "### Grid search also approves our implemented algorithm for finding C and recommends us the same C as we obtained in the last part .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-lYUkMKWZC5",
        "outputId": "e0ac2c3e-7301-4566-cb89-f83dec28489f"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "clf = make_pipeline(StandardScaler(), SVC(C=0.01,kernel = 'rbf' ,gamma=1e-8))\n",
        "clf.fit(x_train_PCA,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('svc', SVC(C=0.01, gamma=1e-08))])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm6bc82yXizu",
        "outputId": "6149364b-9286-4ebe-dcba-44264dc8c2a8"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = clf.predict(x_test_PCA)\n",
        "\n",
        "matrix = confusion_matrix(y_test,y_pred, labels=[3,2,1,0])\n",
        "print('Confusion matrix : \\n',matrix)\n",
        "\n",
        "tp, fn, fp, tn = confusion_matrix(y_test,y_pred,labels=[3,2,1,0])\n",
        "print('Outcome values : \\n', tp, fn, fp, tn)\n",
        "\n",
        "matrix = classification_report(y_test,y_pred,labels=[3,2,1,0])\n",
        "print('Classification report : \\n',matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix : \n",
            " [[70  0  0  0]\n",
            " [17  0  0  0]\n",
            " [28  0  0  0]\n",
            " [25  0  0  0]]\n",
            "Outcome values : \n",
            " [70  0  0  0] [17  0  0  0] [28  0  0  0] [25  0  0  0]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           3       0.50      1.00      0.67        70\n",
            "           2       0.00      0.00      0.00        17\n",
            "           1       0.00      0.00      0.00        28\n",
            "           0       0.00      0.00      0.00        25\n",
            "\n",
            "    accuracy                           0.50       140\n",
            "   macro avg       0.12      0.25      0.17       140\n",
            "weighted avg       0.25      0.50      0.33       140\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwM4KAg1_kdz"
      },
      "source": [
        "### since RBF kernel can classify non-separable Datasets , We expect to have better model with RBF kernel . As we see Accuracy has been better with RBF kernel rather than linear SVM . "
      ]
    }
  ]
}